有参数模型：假设在有限集中的参数 $\theta$ ，预测自变量，数据集都相互独立

![image-20230125094353329](5.基于样例的推理/image-20230125094353329.png)

# 非参数模型

## K-近邻算法(KNN)——k-nearest neighbor

无参数有监督模型，用于分类和预测

![image-20230125094612753](5.基于样例的推理/image-20230125094612753.png)

K表示距离给定点最近的k个点

- K为偶数时，根据距离判断

  ![image-20230125094931155](5.基于样例的推理/image-20230125094931155.png)

![image-20230125095135710](5.基于样例的推理/image-20230125095135710.png)

- K过于小，可能出现过拟合
- K过于大，则无法分类效果不好

### K-NN分类

> 划分空间

![image-20230125095418453](5.基于样例的推理/image-20230125095418453.png)

做连接两个点的直线，过中点做分界线(面)，将空间划分为多个区域，若某一个点 $(x_1^{(i)},x_2^{(i)})$ 落在某个区域时，分为该区域所属的类

### K-NN用于预测

分类问题， $y$ 为离散值。找目标点 $x'$ 最近的 $k$ 个点，取平均值 ![image-20230125100135132](5.基于样例的推理/image-20230125100135132.png) 

![image-20230125100221233](5.基于样例的推理/image-20230125100221233.png)

计算算术均值，前提是假设各点对决策的贡献相等

![image-20230125100613398](5.基于样例的推理/image-20230125100613398.png)

计算加权平均，将各点权重(各个点到目标点的距离不同)考虑进决策

![image-20230125100821097](5.基于样例的推理/image-20230125100821097.png)

### 距离定义

> 特征的数学距离与人的认知距离不同，ML面向人的认知距离

![image-20230125101239483](5.基于样例的推理/image-20230125101239483.png)

- 对称性：
- 自相似性
- 正性分离
- 三角不等式

#### 常用距离定义

欧氏距离：![image-20230125101535207](5.基于样例的推理/image-20230125101535207.png)

曼哈顿距离：

![image-20230125101554478](5.基于样例的推理/image-20230125101554478.png)

闵可夫斯基距离：

![image-20230125101900498](5.基于样例的推理/image-20230125101900498.png)

#### 汉明距离

度量二进制数据的距离

按位异或，1的个数为汉明距离，表示两个二进制数有多少位不同

![image-20230125102129638](5.基于样例的推理/image-20230125102129638.png)

![image-20230125102140276](5.基于样例的推理/image-20230125102140276.png)

#### 自定义距离

自定义多条特征，关注每个数据在不同特征上的异同

## 朴素贝叶斯

![image-20230125102856705](5.基于样例的推理/image-20230125102856705.png)

朴素贝叶斯：假设给定的多个特征相互独立

![image-20230125103046662](5.基于样例的推理/image-20230125103046662.png)

![image-20230125103147116](5.基于样例的推理/image-20230125103147116.png)

 ![image-20230125160237144](5.基于样例的推理/image-20230125160237144.png)

![image-20230125160335305](5.基于样例的推理/image-20230125160335305.png)

![image-20230125103334259](5.基于样例的推理/image-20230125103334259.png)

![image-20230125103345067](5.基于样例的推理/image-20230125103345067.png)

![image-20230125103441229](5.基于样例的推理/image-20230125103441229.png)

![image-20230125160404233](5.基于样例的推理/image-20230125160404233.png)

---

![image-20230125161020272](5.基于样例的推理/image-20230125161020272.png)

![image-20230125161025180](5.基于样例的推理/image-20230125161025180.png)

![image-20230125161034778](5.基于样例的推理/image-20230125161034778.png)

![image-20230125161109599](5.基于样例的推理/image-20230125161109599.png)

![image-20230125161125546](5.基于样例的推理/image-20230125161125546.png)

![image-20230125161143531](5.基于样例的推理/image-20230125161143531.png)

![image-20230125161224901](5.基于样例的推理/image-20230125161224901.png)

---

垃圾过滤

分类：$y\in \{0,1\}$ 表示是否为垃圾邮件；1表示垃圾邮件，0表示正常邮件

用词汇表向量 $x\in \{0,1\}^{50000}$ 表示词汇表中的50000个词是否出现在邮件中

![image-20230125161832782](5.基于样例的推理/image-20230125161832782.png)

![image-20230125161935470](5.基于样例的推理/image-20230125161935470.png)

![](5.基于样例的推理/image-20230125161505127.png)

给定一个词，在垃圾邮件中出现的概率

![image-20230125162030348](5.基于样例的推理/image-20230125162030348.png)

![image-20230125162232510](5.基于样例的推理/image-20230125162232510.png)

给定一个词，在正常邮件中出现的概率

![image-20230125162436183](5.基于样例的推理/image-20230125162436183.png)

![image-20230125162512572](5.基于样例的推理/image-20230125162512572.png)

所有邮件中垃圾邮件占比

![image-20230125162614429](5.基于样例的推理/image-20230125162614429.png)

对于从未出现在单词表中的词汇，处理方法

- ![image-20230125163321414](5.基于样例的推理/image-20230125163321414.png)

  v为词汇表中词汇数量

- ![image-20230125163630223](5.基于样例的推理/image-20230125163630223.png)

  \sigma 很小
