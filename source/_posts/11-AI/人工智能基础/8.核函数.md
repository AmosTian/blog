# 核函数

## 问题

![image-20230127002620240](8.核函数/image-20230127002620240.png)

条件优化

![image-20230127094337062](8.核函数/image-20230127094337062.png)

## 无条件优化

![image-20230127094628097](8.核函数/image-20230127094628097.png)

![image-20230127094651229](8.核函数/image-20230127094651229.png)

## 等式条件

![image-20230127095204553](8.核函数/image-20230127095204553.png)

f(x)等高线 

![image-20230127095512909](8.核函数/image-20230127095512909.png)

f(x)梯度

![image-20230127095821076](8.核函数/image-20230127095821076.png)

![image-20230127095725699](8.核函数/image-20230127095725699.png)

内积表示相对位置，用夹角表示正负\>0 表示沿梯度方向移动

![image-20230127095841138](8.核函数/image-20230127095841138.png)



h(x)梯度

![image-20230127100413100](8.核函数/image-20230127100413100.png)

 函数与约束的梯度关系：移动方向垂直于约束的梯度

![image-20230130084435015](8.核函数/image-20230130084435015.png)

![image-20230127103436472](8.核函数/image-20230127103436472.png)

对于最优情况，约束的梯度与f(x) 的梯度平行

![image-20230127101000645](8.核函数/image-20230127101000645.png)

![image-20230127103718263](8.核函数/image-20230127103718263.png)

---

![image-20230127110526060](8.核函数/image-20230127110526060.png)

### 高维空间

![image-20230127110814862](8.核函数/image-20230127110814862.png)

![image-20230127111223101](8.核函数/image-20230127111223101.png)

![image-20230127111406250](8.核函数/image-20230127111406250.png)

## 不等式优化

![image-20230127213113368](8.核函数/image-20230127213113368.png)

1. 最优值在限制条件内，按全局最优

![image-20230127214949211](8.核函数/image-20230127214949211.png)

![image-20230127215653343](8.核函数/image-20230127215653343.png)

2. 最优值在限制条件外：等式优化

![image-20230127220919987](8.核函数/image-20230127220919987.png)

![image-20230127221026086](8.核函数/image-20230127221026086.png)

前两种情况总结

![image-20230127222052902](8.核函数/image-20230127222052902.png)

![image-20230127221846815](8.核函数/image-20230127221846815.png)

![image-20230127221912853](8.核函数/image-20230127221912853.png)

![image-20230127221937731](8.核函数/image-20230127221937731.png)

---

## 全局优化

![image-20230127222453935](8.核函数/image-20230127222453935.png)

![image-20230127222459302](8.核函数/image-20230127222459302.png)

---

![image-20230127223753618](8.核函数/image-20230127223753618.png)

![image-20230127223939785](8.核函数/image-20230127223939785.png)

- 若最优值在b允许的区域内，则取\lambda=0，求f(x) 的全局最优
- 若最优值在b允许的区域外，则取 \lambda>0，g(x)=0，

![image-20230127224749631](8.核函数/image-20230127224749631.png)

![image-20230130100023619](8.核函数/image-20230130100023619.png)

- 参数最大的条件下，使函数值最小
- x最小的条件下，使函数值最大

# SVM

## 概念

超平面

![image-20230127230456917](8.核函数/image-20230127230456917.png)

![image-20230127230506215](8.核函数/image-20230127230506215.png)

预测

![image-20230127230840572](8.核函数/image-20230127230840572.png)、

![image-20230127230856480](8.核函数/image-20230127230856480.png)

![image-20230127231139216](8.核函数/image-20230127231139216.png)

线性函数的法向量

![image-20230128090509405](8.核函数/image-20230128090509405.png)

## 目标

找到一个超平面，使两类之间的间距最大

![image-20230128090930452](8.核函数/image-20230128090930452.png)

![image-20230128091024697](8.核函数/image-20230128091024697.png)

![image-20230128092004530](8.核函数/image-20230128092004530.png)

通过对数据进行等比缩放，将每个数据映射到超平面 +-1 的平面上

若数据分类正确，则有 y(w^T+b)>0 

对于新数据，一定有 $y^{(i)}[w^Tx^{(i)}+b] \ge1$    

![image-20230128093545399](8.核函数/image-20230128093545399.png)

## 间距的构造

w为法向量，与超平面垂直，法向量过-1超平面上一点与+1超平面上的点交于-1

![image-20230128095438546](8.核函数/image-20230128095438546.png)

![image-20230128095446241](8.核函数/image-20230128095446241.png)

![image-20230128095739283](8.核函数/image-20230128095739283.png)

![image-20230128100042572](8.核函数/image-20230128100042572.png)

![image-20230128100307300](8.核函数/image-20230128100307300.png)

## SVM分类问题

![image-20230128100517949](8.核函数/image-20230128100517949.png)

- 最大的分类间距
- 并且分类正确

![image-20230128100646173](8.核函数/image-20230128100646173.png)

将训练数据作为限制条件

![image-20230130100910110](8.核函数/image-20230130100910110.png)

取定参数，则使L函数值最小的 $x^*$ 也取定 

- 在\alpha最大时，求使L最小的 w,b 的值

  ![image-20230130104153646](8.核函数/image-20230130104153646.png)

- 在x最小时，求使L最大的\alpha值

  ![image-20230130102912782](8.核函数/image-20230130102912782.png)

---

模型对数据判对时，训练数据应远离边界![image-20230130111957430](8.核函数/image-20230130111957430.png)>1

![image-20230130112012423](8.核函数/image-20230130112012423.png)<0，即 $(x^{(i)},y^{(i)})$ 在不等式范围内

要使L函数值最大，则\alpha=0，

---

若部分数据在边界上，此时，![image-20230130112654446](8.核函数/image-20230130112654446.png)=0 ，为等式优化，\alpha>0，x与\alpha可相互表示

转化为对偶形式才方便解答：将wb的问题，用\alpha代替 ，只需优化关于 \alpha 的参数函数

![image-20230130101550113](8.核函数/image-20230130101550113.png)

![image-20230130101818630](8.核函数/image-20230130101818630.png)

![image-20230130102205073](8.核函数/image-20230130102205073.png)

![image-20230130102405103](8.核函数/image-20230130102405103.png)

![image-20230130102540277](8.核函数/image-20230130102540277.png)

对偶形式

![image-20230130102608547](8.核函数/image-20230130102608547.png)

![image-20230130102801478](8.核函数/image-20230130102801478.png)

![image-20230130103250435](8.核函数/image-20230130103250435.png)

![image-20230130105429569](8.核函数/image-20230130105429569.png)

![image-20230130111209537](8.核函数/image-20230130111209537.png)

- 针对在边界上的点——支持向量

结论：边界上的点对决策很重要，称为支持向量，权重>0，其他的点权重=0

SVM是线性模型的优化，目标：找到一个线性函数，使边界的间距最大。通过计算，边界上的点对计算很重要，称为支持向量，正确分类的点权重置为0

## SVM例题

![image-20230130114857011](8.核函数/image-20230130114857011.png)

![image-20230130115002527](8.核函数/image-20230130115002527.png)



---

![image-20230130120012674](8.核函数/image-20230130120012674.png)

![image-20230130120332535](8.核函数/image-20230130120332535.png)

![image-20230130120802835](8.核函数/image-20230130120802835.png)

![image-20230130120906060](8.核函数/image-20230130120906060.png)

![image-20230130121008186](8.核函数/image-20230130121008186.png)

故最优值不在约束范围内，所以必然有参数为0

![image-20230130121559803](8.核函数/image-20230130121559803.png)

![image-20230130121620509](8.核函数/image-20230130121620509.png)

![image-20230130121742724](8.核函数/image-20230130121742724.png)

![image-20230130121819897](8.核函数/image-20230130121819897.png)

![image-20230130121839115](8.核函数/image-20230130121839115.png)



# 核方法

SVM问题中，数据线性可分才可找到分界线

 最大优化方法，核心是求内积，

![image-20230130122031541](8.核函数/image-20230130122031541.png)

将特征的值映射到另一方向

对于数据不可分的空间，通过核方法，将数据映射到可分空间

![image-20230130122450601](8.核函数/image-20230130122450601.png)

![image-20230130122534565](8.核函数/image-20230130122534565.png)

# SVM与线性模型关系

逻辑斯蒂回归

![image-20230130124442333](8.核函数/image-20230130124442333.png)

![image-20230130124557137](8.核函数/image-20230130124557137.png)

![image-20230130124714159](8.核函数/image-20230130124714159.png)

线性模型正则化：损失函数+正则项

正则化：将正则项作为约束，先有损失函数再做正则化

SVM：将损失函数作为约束，直接将正则化系数变为最小，再把损失函数作为约束

 ![image-20230130125452438](8.核函数/image-20230130125452438.png)

### 将最小转化为最大

![image-20230130130303030](8.核函数/image-20230130130303030.png)

找到所有点 ，在w方向上投影比较大

