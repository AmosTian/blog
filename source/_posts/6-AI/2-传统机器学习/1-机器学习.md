---
categories:
  - AI
  - 机器学习
tags:
  - AI
  - 机器学习
top: 8
mathjax: true
title: 1. 机器学习绪论
abbrlink: 1771285239
date: 2023-08-21 15:27:44
---

[TOC]

---

机器学习是计算机基于数据构建概率统计模型并运用模型对数据进行预测和分析的学科

根据输入输出类型的不同，机器学习分为：分类问题，回归问题，标注问题三类

过拟合是机器学习中不可避免的，可通过选择合适的模型降低影响

监督学习是机器学习的主流任务，包括生成方法和判别方法两类



<!--more-->

## 1.0 机器学习的认知

### 1.0.1 对学科范畴的明确

科学：是什么，为什么可以

技术：怎么做

工程：做得多快好省

应用

机器学习更多的是一门科学与技术

### 1.0.2 总体认知

人类的学习机制是一种 **基于经验的学习方式**，即从大量现象、经验(数据)中提取规律(模型)，利用规律(模型)对新情况做出有效决策。

![image-20231225155418249](1-机器学习/image-20231225155418249.png)

机器学习也是一种基于经验的学习方式，研究内容是如何从数据中产生模型(如何提取规律)，即对 **学习算法** 的研究。在确定学习算法后，就能基于经验生成 **模型** (规律)，在面对新样本时模型会给出相应决策。 同时，机器学习也是一种 **PAC学习** ，由于机器学习的问题一般是真实数据分布未知、且目标函数也未知，所以我们降低了对学习算法能力的期望，希望他能在多项式时间中根据有限样本集给出近似正确模型。

学习过程可以看作学习算法运用数据在模型 **假设空间** $\mathcal{H}$ (hypothesis) 中搜索 $\hat{f}$ 用以近似 $f$ 的过程。搜索目标是找到与训练集最匹配的 **假设** (某个学习算法下超参数确定的模型)。有很多 **策略**(与训练集的匹配原则) 可以对这个假设空间进行搜索，利用 **优化算法** ，可以更快地确定最匹配的假设。

通常认为样本空间中全体样本服从某个未知的分布 $\mathcal{D}$ (训练数据集、测试数据集与未来数据集都来源于这个分布) ，且样本之间独立同分布(一个样本不影响另一个样本的产生)。机器学习的目标是使学得的模型更好地适用于 *新样本*，即关注模型的 **泛化能力**。因此，**采样方法** 是影响模型泛化能力的一个重要因素(希望训练集能很好地反映样本空间的特性)。

在现实问题中，学习过程基于有限样本的训练集，但可以准确描述这一训练集的假设有很多(来源于不同学习算法的模型或同一学习算法超参数不同的模型)，即对于某一个实际问题，存在一个 **假设集**。由 **丑小鸭定理** 可知，即使是这一假设集中的假设差距也很大。**归纳偏好** 是学习算法在假设空间中对假设进行选择的原则，即学习算法本身做出的 “什么模型更好” 的假设。

> 首先要解决什么学习算法更好

一个学习算法 $\mathcal{L}_a$ 基于某种归纳偏好产生了对应的模型 $A$ ，学习算法 $\mathcal{L}_b$ 基于另一种归纳偏好产生了对应的模型 $B$ ，对于一些问题，$A$ 优于 $B$ ；一定存在另一些问题， $B$ 优于 $A$ 。换言之，无论学习算法 $\mathcal{L}_a$ 多聪明、$\mathcal{L}_b$ 多笨拙，二者对于所有潜在的问题其期望性能都相同，即 **没有免费午餐(NFL)** 定理。

NFL定理的一个重要前提是所有问题出现的可能性相等或所有问题同样重要，但实际情况是我们只关注自己试图解决的问题。机器学习中，一个问题定义为给定输入域与输出域，要找到映射关系 $\mathcal{X}\mapsto \mathcal{Y}$ 。问题不同，则刻画问题的数据也是不一样的，生成数据 $\mathcal{X}$ 的分布 $f(\cdot)$ 也是不同的，而在不同分布的数据上进行数据分析所使用的技术肯定也不一样。我们希望找到对于该问题最好的解决方案，至于这个解决方案在其他问题上的好坏并不关注。故学习算法没有绝对的优劣之分，只有对当前问题的适配程度之分，常见的各种经典算法，只是在大部分问题上表现不错的算法，并不适合每一个问题。

学习算法自身的归纳偏好与问题是否匹配有决定性作用，要 **具体问题具体分析** ，机器学习的最优学习算法往往来自于：按需设计、度身定制。

> 其次是选择哪个模型能更好的解决当前问题

最常用的归纳偏好是 **奥卡姆剃刀** （模型越简单越好），但解决什么模型是简单的也不简单。

怎么评价模型好坏？

1. 问题要什么结果
2. 给出的结果是不是当前问题需要的结果

NFL：只需要给出当前问题需要的结果即可，不需要关注是否能给出其他问题需要的结果

总体上，我们希望模型能很好地适应当前问题的新样本，即有较强的 **泛化能力** 。模型的泛化能力如何评价？





















## 1.1 机器学习概念

### 1.1.1 定义

> A computer program is said to learn from E with respect to some class of tasks T and performance measure P ,if its performance at tasks T as measured by P improves with experience E.

经典定义（1997）：研究如何通过计算的手段，利用经验(数据)及统计方法提高系统性能

计算机科学是关于算法的科学：机器学习是对学习算法的设计，分析与应用的学科

数据分析角度定义：机器学习是利用计算机进行数据分析的科学，研究 **计算机基于数据构建概率统计模型**，并 **运用该模型对数据进行预测与分析** 

![image-20231226110115458](1-机器学习/image-20231226110115458.png)

### 1.1.2 机器学习理论基础—PAC学习

**计算学习理论** 是通过计算研究学习的理论，能够分析问题难度、计算模型能力，为学习算法提供理论保证，并指导机器学习模型和学习算法的设计。其基础理论为 **概率近似正确** (PAC Probably Approximately Correct) 
$$
P(\vert \hat{f}(x)-y\vert\le \varepsilon)\ge 1-\delta
$$
对于一个数据 $x$ ，其真实结果为 $y$ ，通过假设 $\hat{f}(\cdot)$ 可以得到一个预测结果。我们希望假设模型越准越好，即预测结果与真实结果差距 $\varepsilon$ 越小越好，当 $\varepsilon=0$ 时，意味着假设绝对正确。但并不能保证每次运行都能获取绝对正确的假设，只能希望每次以很高的概率得到这个准确的假设。

- 为什么是概率正确模型，而不是拿到绝对正确模型

  从计算角度理解：机器学习解决的问题是NP(非多项式时间可解)问题

  从问题角度理解：机器学习解决的问题通常是高度不确定性、高度复杂性且不知道怎么去解决。当知识不能精确给出结果时，从数据中分析，希望从数据中给出答案，此时不能要求这个答案是百分百准确。

在解决实际问题时，我们用 **泛化误差** $\mathcal{G}(f)$ 量化假设 $\hat{f}(\cdot)$ 对未知数据的预测能力。 泛化误差衡量的是期望误差与经验误差的差异，但由于真实的数据分布未知、且目标函数也未知，所以需要降低对学习算法能力的期望。只期望学习算法以一定的概率学习到一个近似正确的假设， 即 **PAC学习：在多项式时间内从合理数量的训练数据中学习到一个近似正确的 $\hat{f}(x)$ ** 。

- 近似正确：一个假设 $\hat{f}\in \mathcal{H}$ 是近似正确的，是指其在泛化误差 $\mathcal{G}(\hat{f})$ 小于一个界限 $\varepsilon(0<\varepsilon <\frac{1}{2})$ 

- 概率：一个学习算法  $\mathcal{A}$ 有可能以 $1-\delta$ 的概率学习到这样一个近似正确的假设 $\hat{f}$ ，$0<\delta<\frac{1}{2}$

$$
P\left(\left[R_{exp}(\hat{f})-R_{emp}(\hat{f})\right]\le \varepsilon\right)\ge 1-\delta
$$

其中 $\varepsilon,\delta$ 是和样本数量 $N$ 以及假设空间 $\mathcal{F}$ 相关的变量。如果固定 $\varepsilon,\delta$ 可以反过来计算所需的样本数量
$$
N(\varepsilon,\delta)\ge \frac{1}{2\varepsilon^2}(\log \vert \mathcal{F}\vert+\log\frac{2}{\delta})
$$

- 模型越复杂($\vert \mathcal{F}\vert$ 越大)，模型的泛化能力越差，要达到相同的泛化能力，越复杂的模型需要的样本数量越多

#### 机器学习前提

对于一个问题，没有明确可定义的规则或知识可以解决

已知该问题存在可学习的模型

有某种形式的数据供学习

#### NIF定理——学习算法间的比较

> 没有免费的午餐：学习算法对所有潜在问题的期望性能相同

假设样本空间 $\mathcal{X}$ 与假设空间 $\mathcal{H}$ 都是离散的。令 $P(h\vert X,\mathcal{L}_a)$ 表示算法 $\mathcal{L}_a$ 基于训练数据 $X$ 产生的假设 $h$ 的概率，令 $f$ 为样本空间的某个真实分布函数。对于学习算法 $\mathcal{L}_a$ 在训练集外的误差表示为
$$
E_{ote}(\mathcal{L}_a\vert X,f)=\sum\limits_{h\in \mathcal{H}}\sum\limits_{x\in \mathcal{X}-x}P(x)\mathbb{I}(h(x)\neq f(x))P(h\vert X,\mathcal{L}_a)
$$
而对于一个二分类问题，考虑其真实目标函数可以是任意一个 $\mathcal{X}\mapsto\{0,1\}$ 的函数(由样本出现的组合表征某一个分布)，若所有分布 $f$ 出现的可能相同，即按均匀分布对学习算法 $\mathcal{L}_a$ 的训练集外误差求和
$$
\begin{aligned}
\sum\limits_{f}E_{ote}(\mathcal{L}_a\vert X,f)&=\sum\limits_{f}\sum\limits_{h\in \mathcal{H}}\sum\limits_{x\in \mathcal{X}-x}P(x)\mathbb{I}(h(x)\neq f(x))P(h\vert X,\mathcal{L}_a)\\
&=\sum\limits_{x\in \mathcal{X}-x}P(x)\sum\limits_{h\in \mathcal{H}}P(h\vert X,\mathcal{L}_a)\sum\limits_{f}\mathbb{I}(h(x)\neq f(x))\\
&=\sum\limits_{x\in \mathcal{X}-x}P(x)\sum\limits_{h\in \mathcal{H}}P(h\vert X,\mathcal{L}_a)\frac{1}{2}2^{\vert\mathcal{X}\vert}\\
&=\frac{1}{2}2^{\vert\mathcal{X}\vert}\sum\limits_{x\in \mathcal{X}-x}P(x)\sum\limits_{h\in \mathcal{H}}P(h\vert X,\mathcal{L}_a)\\
&=\frac{1}{2}2^{\vert\mathcal{X}\vert}\sum\limits_{x\in \mathcal{X}-x}P(x)\
\end{aligned}
$$
即总误差与学习算法无关，$\sum\limits_{f}E_{ote}(\mathcal{L}_a\vert X,f)=\sum\limits_{f}E_{ote}(\mathcal{L}_b\vert X,f)$

- 函数空间大小：对某个二分类问题，假设样本空间为 $\mathcal{X}=\{x_a,x_b\}$ ，所有可能的真实分布 $f$
  $$
  f_1:f_1(x_a)=0,f_1(x_b)=0\\
  f_2:f_2(x_a)=0,f_2(x_b)=1\\
  f_3:f_3(x_a)=1,f_3(x_b)=0\\
  f_4:f_4(x_a)=1,f_4(x_b)=1\\
  $$
  即共有 $2^{\vert \mathcal{X}\vert}=2^2=4$ 种样本组合，也就是有四个不同的分布函数才能产生这些样本组合，此时不管学习算法 $\mathcal{L}_a$ 得出的模型 $h(x)$ 对每个样本预测为0还是1，总有一半的概率使 $\mathbb{I}(\cdot)=1$ ，即 $\sum\limits_{f}\mathbb{I}(h(x)\neq f(x))=\frac{1}{2}2^{\vert \mathcal{X}\vert}$

**对于某个问题，所有学习算法产生的所有模型都是错的，但有些模型是有用的** 

没有最好的解决方案，只有最合适的解决方案

### 1.1.3 术语

数据集：训练集(training data set)，测试集(test data set) 都知道结果(label)，但用途不同

数据：

- 示例(instance)：对对象某些性质的描述，不同的属性值有序排列得到的向量

  - 属性(attribute)，特征(feature)：被描述的性质

  - 属性值

- 样例(example)：有结果

  标签(label)：示例的对应的结果

- 样本(sample)

不同的属性之间视为相互独立，每个属性都代表了不同的维度，这些属性共同张成了 **特征空间** ，属性空间，输入空间

每个示例都可以看做特征空间中的一个向量—— **特征向量** (feature vector)

标记空间，输出空间

### 1.1.4 机器学习过程

1. 得到有限的训练数据集合
2. 确定学习模型的集合——Model
3. 确定模型选择的准则(评价准则)——Strategy 风险
4. 实现最优模型求解算法——Algorithm 最优化理论
5. 运行算法 $\Rightarrow$ 最优化模型
6. 预测新数据，分析

**eg** 

![image-20230831150246852](1-机器学习/image-20230831150246852.png)

需要学习的未知潜藏模式：批准信用卡是否对银行有利(good/bad)

![image-20230831150650973](1-机器学习/image-20230831150650973.png)

![image-20230831150729361](1-机器学习/image-20230831150729361.png)

![image-20230831150842016](1-机器学习/image-20230831150842016.png)

## 1.2 ML特点

- 以计算机及网络为平台
- 以数据为研究对象
- 目的是对数据进行分析和预测
- 以方法为中心：基于数据构建模型
- 交叉学科

### 1.2.1 以数据为研究对象

提取数据特征，将数据特征抽象为模型，利用模型对未知数据进行分析预测。

前提：同类数据有一定统计规律，可以用概率统计的方法处理
$$
\begin{array}{c|c}
\hline
随机变量&数据特征\\
概率分布&数据的统计规律\\
变量/变量组&一个数据点\\
\hline
\end{array}
$$

### 1.2.2 目标

机器学习目标：根据已有的训练数据推导出所有数据的模型，并根据得出的模型实现对未知测试数据的最优预测

![image-20230831145251583](1-机器学习/image-20230831145251583.png)

总目标：学习什么样的模型，如何构建模型(怎么评价模型的优劣)

### 1.2.3 方法——基于数据构建模型

从给定的、有限的、用于学习的训练数据集(Training data)出发，且训练集中的数据具有一定的统计特性，可以视为满足 **独立同分布** 的样本。

假设待学习的模型属于某个函数集合——假设空间(Hypothesis space)

应用某个评价准则(Evaluation criterion)——策略

通过算法(Algorithm)选取一个最优化模型

使它在已知的训练集和测试集上在给定的评价标准下有最优预测

## 1.3 统计学习三要素

**方法=模型+策略+算法**

- 模型 from  Hypothesis space：选定某一类模型——SVM/EM
- 策略Strategy：模型选择标准、准则evaluation criterion——$J(\theta)$ ，风险最小化
- 算法Algorithm：怎样快速确定模型

### 1.3.1 模型

$$
监督学习\begin{cases}
条件概率\\
决策函数
\end{cases}\Rightarrow 假设空间\mathcal{F}：模型的所有可能的集合
$$

$$
\begin{cases}
\mathcal{F}=\{f\vert Y=f(x)\}，由参数决定的参数族\\
\quad决策函数\begin{cases}
线性模型:\omega,b\\
SVM：\omega,b,\alpha\\
EM:\pi,\theta
\end{cases}\\\\
\mathcal{F}=\{f\vert Y=f_{\theta}(X),\theta\in R^m\}\\
\quad P_{\theta}(Y\vert X)条件概率分布\begin{cases}
用于分类，预测arg\max\limits_{y}P(Y\vert X)
\end{cases}
\end{cases}
$$

### 1.3.2 策略

> 按什么样准则选择具有最优参数组的模型

损失：度量模型 **一次** 预测的好坏

风险：度量 **平均** 意义下预测的好坏

#### 常用损失函数

预测模型得出的预测值 $f(x)$ 与 $y$ 有差距，用损失函数 $\mathcal{L}(y,f(x))$ 表示
$$
\begin{cases}
0-1&\mathcal{L}(y,f(x))=\begin{cases}
1,Y\neq \hat{f}(x)\\
0,Y=\hat{f}(x)
\end{cases}\\
&I(Y\neq \hat{f}(x))表示不等则为1\\\\
平方损失&\mathcal{L}(y,f(x))=\frac{1}{2}(y-f(x))^2——放大损失\\\\
绝对损失&\mathcal{L}(y,f(x))=\vert y-f(x)\vert\\\\
对数损失&\mathcal{L}(y,P(Y\vert x))=-logP(y\vert x)
\end{cases}
$$

对数损失——交叉熵损失

> 一般用于分类问题

假设样本标签 $y\in [1,\cdots,C]$ 为离散类别，模型 $f(x;\theta)\in [0,1]^C$ 的输出为类别标签的条件概率
$$
p(y=c\vert x;\theta)=f_c(x;\theta)\\
且满足 f_c(x;\theta)\in [0,1]\qquad \sum\limits_{c=1}^Cf_c(x;\theta)=1
$$
用 one-hot 向量 $y$ 表示样本标签的真实条件概率分布 $p_r(y\vert x)$ ，记为 $y_c$

对于两个概率分布，一般用交叉熵来衡量二者差异
$$
\begin{aligned}
\mathcal{L}(y,f(x;\theta))&=-y^T\log f(x;\theta)\\
&=-\sum\limits_{c=1}^Cy_clogf_c(x;\theta)
\end{aligned}
$$
![image-20230921172344741](1-机器学习/image-20230921172344741.png)

由于 $y$ 是 one-hot 向量，也可写作
$$
\mathcal{L}(y,f(x;\theta))=-\log f_y(x;\theta)
$$
其中 $f_y(x;\theta)$ 可以看做真实类别 $y$ 的似然函数

#### 风险函数(期望损失)

> 关于联合分布的期望损失(expectation risk)

$$
\begin{aligned}
R_{exp}(f)&=E\left[\mathcal{L}(y,f(x))\right]\quad 期望损失对P(Y\vert X) 进行评价\\
&=\int_{\mathcal{XY}}\mathcal{L}(y,f(x))P(X,Y)dxdy\\
\end{aligned}
$$

表示 $f(x)$ 关于联合分布 $P(X,Y)$ 的平均意义下的损失

$R_{exp}(f)$ 不可计算：$P(X,Y)$ 未知。

- 若 $P(X,Y)$ 已知，则可通过 $P(Y\vert X)$ 计算
- 病态：期望损失用到 $P(Y\vert X)$

**期望风险最小化策略**

- 后验概率最大化策略

  朴素贝叶斯

  逻辑斯蒂回归

#### 经验函数(平均损失)

> empirical risk

$D=\{(x_1,y_1),(x_2,y_2),\cdots,(x_n,y_n)\}$

$$
R_{emp}(f)=\frac{1}{n}\sum\limits_{i=1}^n\mathcal{L}(y_i,f(x_i))\xrightarrow{n\rightarrow\infty}R_{exp}(f)
$$

---

**极大似然估计是经验风险最小化策略** 
$$
x_1,x_2,\cdots,x_n\overset{iid}{\sim}P(X)，求X服从分布的参数
$$
可观测样本的联合概率分布一定是最大（小概率事件原理）可采样的，$P$ 越大，联合概率 $P$ 越大
$$
P(x_1)P(x_2),\cdots,P(x_n)=\prod\limits_{i=1}^nP(x_i)\\
\max\prod\limits_{i=1}^nP(x_i)=max\sum\limits_{i=1}^nlogP(x_i)=-min\sum\limits_{i=1}^nlogP(x_i)
$$
可得损失函数，也即对数损失函数。即经验风险最小化策略

---

由于现实中 $N$ 很小，需要对 $R_{emp}$ 矫正
$$
\begin{cases}
经验风险最小化\\
结构风险最小化+正则化项，控制过拟合程度
\end{cases}
$$

##### 经验风险最小化和结构风险最小化

**样本量足够大，用经验风险最小化策略** —— empirical risk minimization,ERM
$$
\min\limits_{f\in \mathcal{F}} \frac{1}{n}\sum\limits_{i=1}^nL(y_i,f(x_i))
$$
**样本容量小** ——过拟合 $\leftarrow$ 参数过多

过拟合解决思路 $\begin{cases}加样本容量\\加正则化项\end{cases}$ 

> 用结构风险最小化策略——structural risk minimization SRM

$$
R_{srm}(f)=\frac{1}{n}\sum\limits_{i=1}^nL(y_i,f(x_i))+\lambda J(f)\begin{cases}
f越简单，参数量越少,J(f)越小\\
f越复杂，参数量越多，J(f)越大
\end{cases}
$$

- $\lambda\ge 0$ 用于权衡 $srm$ 与 $erm$ 

$$
\min\limits_{f\in \mathcal{F}}\frac{1}{n}\sum\limits_{i=1}^nL(y_i,f(x_i))+\lambda J(f)
$$

### 1.3.3 算法

#### 参数优化

> 用什么样方法，求最优模型

梯度下降 (Gradient Descent) 求损失函数的极值，**最优解**
$$
解析解\rightarrow 数值解\rightarrow 转化为对偶问题
$$

![image-20230920180039385](1-机器学习/image-20230920180039385.png)

学习率是很重要的超参数

![image-20230920181111973](1-机器学习/image-20230920181111973.png)

好的学习率：在初始时，梯度下降快；在接近最优解时，梯度下降慢

---

**随机梯度下降法（Stochastic Gradient Descent）**：在每次迭代时，只采集一个样本
$$
\theta^{[t+1]}=\theta^{[t]}-\alpha\frac{\partial \mathcal{L}(y_n,f(x_n;\theta)) }{\partial \theta},n=1,2,\cdots,N
$$
 当经过足够次数的迭代时，随机梯度下降也可以收敛到局部最优解

优点：每次计算开销小，支持在线学习

缺点：无法充分利用计算机的并行计算能力

最优实践：由于随机取样本，可能导致有些样本一直无法被使用，为提高训练样本的利用率，在实践过程中，先对训练集中的样本随机排序，再按顺序逐个取

![image-20230920205432412](1-机器学习/image-20230920205432412.png)

---

**小批量(Mini-Batch)随机梯度下降法**

随机选取一小部分训练样本来计算梯度并更新参数

既可以兼顾随机梯度下降法的优点，也可以提高训练效率

#### 超参数优化

> 用于定义模型结构或优化策略

常见超参数：聚类算法中的类别个数、梯度下降法中的步长、正则化 项的系数、神经网络的层数、支持向量机中的核函数等

通常是按照人的经验设定，或者通过搜索的方法对一组超参数组合进行不断试错调整．

## 1.4 模型评估与选择

> 噪声数据：训练样本本身还可能包含一些噪声，这些随机噪声会给模型精确性带来误差

机器学习不等价于优化问题

### 1.4.1 经验风险最小化造成过拟合问题

![image-20230921175030939](1-机器学习/image-20230921175030939.png)

#### 过拟合

**原因** ：将噪音数据并入模型

![image-20230124180558581](1-机器学习/image-20230124180558581.png)

> 过拟合：对训练数据拟合程度越高，学习时模型会越复杂（包含的参数过多），从而导致训练误差较低但测试误差较高（失去泛化能力）

- 表现为错把训练数据的特征当做整体的特征

![image-20230124180759001](1-机器学习/image-20230124180759001.png)

多项式复杂度代表模型复杂度与自由度，自由度过高会出现过拟合问题，但过低会出现欠拟合问题

##### 避免过拟合

- 增大样本容量

- 集成学习：训练很多模型，对模型求均值

- 正则化：对模型复杂度加以惩罚
  $$
  W=\sum V(f(x_i,t_i))+\lambda\Omega(f)
  $$

- 交叉验证

#### 欠拟合

> 欠拟合：学习能力太弱，以致于训练数据的基本性质都没学到

在实际的机器学习中，欠拟合可以通过改进学习器的算法克服，但过拟合却无法避免

- 由于训练样本的数量有限，所以具备有限个参数的模型就足以将所有样本都纳入其中。

  但模型的参数越多，与这个模型精确符合的数据也越少，将这样的模型运用到无穷的未知数据中，过拟合的出现便不可避免

### 1.4.2 泛化误差

#### 误差

> 学习器的预测输出与样本真实输出之间的差异被定义为机器学习中的误差

分类问题中，$误差率=\frac{分类错的样本数}{全部样本数}\times 100\%$ 

**训练误差** ：学习器在训练集上的平均误差，经验误差
$$
R_{emp}=\frac{1}{n}\sum\limits_{i=1}^n L(y_i,\hat{f}(x_i))
$$

- 描述输入属性和输出分类之间的相关性，能够判定给定的问题是不是一个容易学习的问题

**测试误差** ：学习器在测试集上的误差
$$
e_{test}=\frac{1}{n'}\sum\limits_{i=1}^{n'} L(y_i,\hat{f}(x_i))
$$

- 反映了学习器对未知测试数据集的预测能力

实用的学习器都是测试误差较低，即在新样本上表现比较好的学习器

eg：

0-1损失 $\mathcal{L}(y,\hat{f}(x))$ 

$e_{test}=\frac{1}{n'}\sum\limits_{i=1}^{n’} I(y_i\neq \hat{f}(x_i))$ 误差率 error

$r_{test}=\frac{1}{n'}\sum\limits_{i=1}^{n’} I(y_i= \hat{f}(x_i))$ 正确率 right

#### 泛化能力

> 模型对未知数据的预测能力

由于测试数据集是有限的，依赖测试误差的评价结果不可行

泛化误差：

![image-20230920211205681](1-机器学习/image-20230920211205681.png)
$$
\mathcal{G}(f)=R_{exp}(f)-R_{emp}(f)
$$
期望风险与经验风险的差异，称为 **泛化误差**

- 当一个模型，经验风险很低，泛化误差(期望风险)很大，则说明发生过拟合
- 一个好的模型，既希望经验风险比较低，也希望泛化误差比较低

$$
R_{exp}(\hat{f})=E_P[\mathcal{L}(Y,\hat{f}(X))]=\int_{\mathcal{XY}}\mathcal{L}(y,\hat{f}(x))\cdot P(x,y)dxdy
$$

由于 $\begin{cases}数据量少，无法用于对全部数据测试\\X,Y联合分布位置\end{cases}$ ，无法计算期望风险，因此，引出比较 **泛化误差上界** 的方法

##### 泛化误差上界

$f$ 的期望风险，$R(f)=E[\mathcal{L}(Y,f(X))]$ 

经验风险， $\hat{R}(f)=\frac{1}{n}\sum\limits_{i=1}^n\mathcal{L}(y_i,f(x_i))$ 

经验风险最小化策略，$f_n=arg \min\limits_{f\in \mathcal{F}} \hat{R}(f)=arg \min\limits_{f\in \mathcal{F}}\frac{1}{n}\sum\limits_{i=1}^n\mathcal{L}(y_i,f(x_i))$

对于 $f_n$ 的泛化能力
$$
R(f)\le \hat{R}(f)+\varepsilon(d;n;\sigma)=\frac{1}{n}\sum\limits_{i=1}^n\mathcal{L}(y_i,f(x_i))+\sqrt{\frac{1}{2n}(\log d+\log\frac{1}{\sigma})}
$$

- 对于任一 $f\in \mathcal{F}$ ，以 $1-\sigma$ 概率上式成立(PAC相关#1.7.1)，$\sigma\in (0,1)$ 

- $d$ 为 $\vert\mathcal{F}\vert,\mathcal{F}=\{f_1,f_2,\cdots,f_d\}$ 

由泛化上界可知，
$$
\begin{cases}
n\uparrow，样本容量越多,泛化误差越小\\
d\downarrow，模型假设空间越少，泛化误差越小\\
\sigma\uparrow，对模型的确信度(1-\sigma)越小，泛化误差越小
\end{cases}
$$
样本多，备选模型少，小范围使用，不信任普适性，则泛化误差小

### 1.4.3 减少泛化误差

优化目标：经验风险最小化

正则化：降低模型复杂度

- 控制模型参数范围，使一些参数趋于0或等于0
- **所有损害优化的方法都是正则化**

#### 增加优化约束—— **结构风险最小化策略**

$$
\min\limits_{f\in \mathcal{F}}\frac{1}{n}\sum\limits_{i=1}^nL(y_i,f(x_i))+\lambda J(f)
$$

#####  $L_1,L_2$ 约束

- $L_2$ 范数——系数尽可能趋于0

  ![image-20230921005723681](1-机器学习/image-20230921005723681.png)
  $$
  \begin{aligned}
  L(\omega)&=\frac{1}{n}\sum\limits_{i=1}^nL(y_i,\hat{f}(x_i))+J(f)\\
  &=\frac{1}{n}\sum\limits_{i=1}^n\left(\hat{f}(x_i)-y_i\right)^2+\frac{\lambda}{2}\Vert \omega\Vert^2_2\\
  &\Vert \omega\Vert_2=\sqrt{\omega_1^2+\omega_2^2+\cdots+\omega_m^2},限制条件 \sum\omega^2\le m
  \end{aligned}
  $$

- $L_1$ 范数——使参数稀疏化
  $$
  \begin{aligned}
  L(\omega)&=\frac{1}{n}\sum\limits_{i=1}^nL(y_i,\hat{f}(x_i))+J(f)\\
  &=\frac{1}{n}\sum\limits_{i=1}^n\left(\hat{f}(x_i)-y_i\right)^2+\lambda\Vert \omega\Vert_1\\
  &\Vert \omega\Vert_1=\vert\omega_1\vert+\vert\omega_2\vert+\cdots+\vert \omega_m\vert
  \end{aligned}
  $$

经验风险较小的模型，正则化项会比较大

- 用于选择经验风险与模型复杂度同时小的模型

> 对于贝叶斯估计，先验概率为正则项

- 复杂模型，先验概率小

- 简单模型，先验概率大

###### 正则化为什么防止过拟合

$$
R_{srm}(\omega)=\frac{1}{n}\sum\limits_{i=1}^nL(y_i,\hat{f}(x_i))+\lambda J(\omega)\begin{cases}
L_1:\Vert \omega\Vert_1=\sum\limits_{i=1}^m\vert \omega_i\vert\\
L_2:\Vert \omega\Vert_2=\sqrt{\sum\limits_{i=1}^m\omega_i^2}
\end{cases}
$$

对于平方损失函数，$\mathcal{L}(\omega)=\frac{1}{n}\sum\limits_{i=1}^n\left[y_i-\hat{f}(x_i)\right]^2+\lambda\Vert \omega\Vert_2^2$ 

正则化项可看做拉格朗日算子，该函数极值点为令 $\begin{cases}\frac{\partial \mathcal{L}}{\partial \omega_i}=0\\\frac{\partial \mathcal{L}}{\partial\lambda}=0\end{cases}$ 的点

也可以对参数和进行约束
$$
\begin{cases}
\min R_{emp}=\frac{1}{n}\sum\limits_{i=1}^n\left[y_i-\hat{f}(x_i)\right]^2\\
s.t. \Vert \omega\Vert_2^2\le m
\end{cases}
$$
KKT条件：
$$
\begin{cases}
min f(x)\\
s.t. \begin{cases}
g_j(x)\le 0,j=1,\cdots,m\\
h_k(x)=0,k=1,\cdots,l
\end{cases}
\end{cases}
$$
构造拉格朗日函数 $L(X;\mu;\lambda)=f(x)+\sum\limits_{j=1}^m\mu_jg_j(x)+\sum\limits_{k=1}^l \lambda_k h_k(x)$

令
$$
\begin{cases}
\frac{\partial L}{\partial x_i}=0\\\\
h_k(x)=0,k=1,\cdots,l\\\\
\frac{\partial L}{\partial \lambda_k}=0\\\\
\sum\mu_jg_j\le 0,j=1,\cdots,m\\\\
\mu_j\ge 0
\end{cases}
$$
$L(\omega)=\frac{1}{n}\sum\limits_{i=1}^n\left[\hat{f}(x_i)-y_i\right]^2+\lambda(\Vert \omega\Vert_2^2-m)$ 
$$
代入KKT条件有\\
\begin{cases}
\frac{\partial L(\omega)}{\partial \omega_i}=0\\
\frac{\partial L}{\partial\lambda}=0
\end{cases}
$$
由此可知，带正则化项与带约束项是一致的

##### 数据增强

#### 干扰优化过程

##### 权重衰减

##### 随机梯度下降

##### 提前停止

> 使用一个验证集来测试每一次迭代的参数在验证集上是否是最优

- 如果在验证集上的错误率不再下降，则停止迭代

![image-20230921010347544](1-机器学习/image-20230921010347544.png)

### 1.4.4 参数取值

参数的取值是影响模型性能的重要因素，同样的学习算法在不同的参数配置下，得到的模型性能会有显著差异

假设一个神经网络有1000个参数，每个参数有10种取值可能，对于每一组训练/测试集就有 $1000^{10}$ 个模型需要考察，因此在调参过程中，主要的问题就是性能与效率的折衷

### 1.4.5 维数诅咒

在高维空间中，同样规模的数据集会变得很稀疏

![image-20230124182919246](1-机器学习/image-20230124182919246.png)

在高维空间，达到与低维空间相同的数据密度需要更大的数据量

### 1.4.6 模型选择

#### 理想模型

逼近 “真”模型 $\begin{cases}参数个数相同\\参数向量相近\end{cases}$

#### 模型复杂度与测试误差

当模型复杂度较低时，测试误差较高

随着模型复杂度增加，测试误差将逐渐下降并达到最小值

之后当模型复杂度继续上升，测试误差会随之增加，对应过拟合的发生

![image-20230904092230170](1-机器学习/image-20230904092230170.png)

在选择模型时，测试集不可见

#### 引入验证集

将训练集分为

- 训练集 Training Set
- 验证集 Validation Set

选择模型：

1. 在训练集上训练不同的模型
2. 选择在验证集上错误最小的模型

#### 数据稀疏——交叉验证

$$
D=\begin{cases}
训练集：训练模型\\
验证集：模型选择\\
测试集：模型评估
\end{cases}
$$

验证集和测试集不用于训练模型

调参（是否过拟合）——评估泛化能力

- 对模型框架定义
- 学习率

> 交叉验证思想在于重复利用有限的训练样本，通过将数据切分成若干子集，让不同的子集分别组成训练集与测试集，并在此基础上反复进行训练、测试和模型选择，达到最优效果。

**交叉验证** 适用于 $\begin{cases}数据量少\\训练数据可重复使用\end{cases}$

![image-20230921163359132](1-机器学习/image-20230921163359132.png)

1. 简单交叉验证

   训练+测试随机划分

2. k折交叉验证

   将数据集分为 $k$ 个大小相等，互不相交的子集，用 $k-1$ 个子集作为训练集，1个用作测试集，进行 $k$ 轮训练，保证每份数据集都被用作测试集，选出 $k$ 次评测中平均测试误差最小的模型

**留一交叉验证** ：一份一个样本

- 折数=样本数

#### 模型选择准则

- 赤池信息量准则(AIC)
- 贝叶斯信息准则(BIC)

#### 偏差-方差分解——模型的量化评价

如何在模型的拟合能力和复杂度之间取得一个较好的平衡

偏差-方差分解为我们提供了一个很好的分析和指导工具

$$
\begin{aligned}
R_{exp}(f)&=E_{(x,y)\sim p_r(x,y)}\left[(y-f(x))^2\right]\\
&\xlongequal{每个点期望风险都应最小}E_{x\sim p_r(x)}\left\{E_{y\sim p_r(y\vert x)}\left[\left(y-f(x)\right)^2\right]\right\}\\
&=E_{x\sim p_r(x)}\left\{E_{y\sim p_r(y\vert x)}\left[(y-E_{y\sim p_r(y\vert x)}[y]+E_{y\sim p_r(y\vert x)}[y]-f(x))^2\right]\right\}\\
&=E_{x\sim p_r(x)}\left\{E_{y\sim p_r(y\vert x)}[(y-E_{y\sim p_r(y\vert x)}[y])^2]+E_{y\sim p_r(y)}\left[(E_{y\sim p_r(y\vert x)}[y]-f(x))^2\right]\right\}\\
&\quad +E_{x\sim p_r(x)}\left\{2E_{y\sim p_r(y\vert x)}[(y-E_{y\sim p_r(y\vert x)}[y])]E_{y\sim p_r(y)}\left[(E_{y\sim p_r(y\vert x)}[y]-f(x))\right]\right\}\\
&\xlongequal{交叉项=0}E_{x\sim p_r(x)}\left\{E_{y\sim p_r(y\vert x)}[(y-E_{y\sim p_r(y\vert x)}[y])^2]+E_{y\sim p_r(y)}\left[(E_{y\sim p_r(y\vert x)}[y]-f(x))^2\right]\right\}\\
&\propto E_{x\sim p_r(x)}\left\{E_{y\sim p_r(y)}\left[(E_{y\sim p_r(y\vert x)}[y]-f(x))^2\right]\right\}\\
&=E_{(x,y)\sim p_r(x,y)}\left[(E_{y\sim p_r(y\vert x)}[y]-f(x))^2\right]
\end{aligned}
$$
$\therefore$ 最优模型为 
$$
f^*(x)=E_{y\sim p_r(y\vert x)}[y]
$$
其损失为
$$
\epsilon=E_{(x,y)\sim p(x,y)}[(y-f^*(x))^2]
$$

- 损失 $\epsilon$ 是由于样本分布以及噪声引起的，无法通过优化模型来减少

综上，期望损失可以分解为
$$
\begin{aligned}
R_{exp}(f)&=E_{(x,y)\sim p_r(x,y)}\left[(y-f(x))^2\right]\\
&=E_{(x,y)\sim p_r(x,y)}\left[(y-f^*(x)+f^*(x)-f(x))^2\right]\\
&=E_{x\sim p_r(x)}\left[\left(f(x)-f^*(x)\right)^2\right]+\epsilon
\end{aligned}
$$
在实际训练模型时，不同的训练集会得到不同的模型

令 $f_D(x)$ 表示在训练集 $D$ 上学习到的模型
$$
\begin{aligned}
E_D\left[(f_D(x)-f^*(x))^2\right]&=E_D\left[(f_D(x)-E_D[f_D(x)]+E_D[f_D(x)]-f^*(x))^2\right]\\
&=\underbrace{\left(E_D[f_D(x)]-f^*(x)\right)^2}_{偏差^2}+\underbrace{E_D\left[\left(f_D(x)-E_D[f_D(x)]\right)^2\right]}_{方差}
\end{aligned}
$$
![image-20230921233545015](1-机器学习/image-20230921233545015.png)

![image-20230921233634364](1-机器学习/image-20230921233634364.png)

最小化风险，等价于最小化偏差与方差之和 

![image-20230921233903350](1-机器学习/image-20230921233903350.png)

- 随模型复杂度增加，偏差减小，方差增大

解决高方差，低偏差

- 集成模型：有效降低方差



## 1.2 学习算法分类

$$
\begin{aligned}
&按任务分类\left\{
\begin{aligned}
&监督学习supervised\quad learning\\
&无监督学习unsupervised\quad learning\\
&半监督学习semi-supervised\quad learning\\
&强化学习reinforced\quad learning\\
&主动学习\\
\end{aligned}
\right.\\\\
&按模型分类\begin{cases}
\begin{cases}
概率模型probabilistic\quad model\\
非概率模型non-probabilistic\quad model\begin{cases}
线性模型 liner\quad model\\
非线性模型non-liner\quad model
\end{cases}
\end{cases}\\
\begin{cases}
参数化方法parameteric\quad model\\
非参数化方法non-parameteric\quad model
\end{cases}
\end{cases}\\\\
&按技巧分类\begin{cases}
贝叶斯:贝叶斯定理Bayesian \quad learning\\
核方法:核函数kernel\quad method
\end{cases}\qquad
按算法分类\begin{cases}
在线学习online\quad learning\\
批量学习batch\quad learning
\end{cases}
\end{aligned}
$$

### 1.2.1 参数化/非参数化方法

参数化：假设模型的参数维度固定

- 感知机
- 朴素贝叶斯
- 逻辑斯蒂回归
- K均值
- 高斯混合模型

非参数化：参数维度不固定，随数据量的增加而增加

- 决策树
- Adaboosting
- K近邻
- 语义分析
- 潜在狄利克雷分配

### 1.2.2 按算法分类

在线学习：一次一个数据，动态调整模型

1. 接收一个输入 $x_t$ ，用已知模型给出 $\hat{f}(x_t)$ 后，得到反馈 $y_t$
2. 系统用损失函数计算 $\hat{f}(x_t)$ 与 $y_t$ 的差异，更新模型

批量学习：一次所有数据，学习模型

---

随机梯度下降感知机
$$
\begin{aligned}
&\omega=\omega-\alpha\frac{\partial l}{\partial \omega}\\
&在线学习：\omega_{i+1}\leftarrow \omega_i-\alpha\frac{\partial l}{\partial \omega}——振荡\\
&批量学习：\omega_{i+1}\leftarrow \omega_i-\alpha\frac{\overline{\partial l}}{\partial \omega}——稳定下降
\end{aligned}
$$
10个数据，$\frac{1}{10}\sum\limits_{i=1}^{10}\frac{\partial L(x_i)}{\partial \omega_i}=\frac{\overline{\partial l}}{\partial \omega}$ 

### 1.2.3 按模型分类

概率模型——条件概率

非概率模型(确定性模型)——决策函数
$$
监督学习\begin{cases}
概率模型：P(y\vert x)——生成模型\\
非概率模型：y=f(x)——判别模型
\end{cases}
$$

#### 概率模型

- 决策树
- 朴素贝叶斯
- 隐马尔科夫模型
- 条件随机场
- 高斯混合模型
- 概率混合模型
- 潜在狄利克雷分配

概率模型的代表为 **概率图模型** 

- 联合概率分布由有向图和无向图表示

- 遵循加法，乘法原则 
  $$
  \begin{cases}
  P(X)=\sum\limits_{y}P(X,Y)\\
  P(X,Y)=P(X)P(Y)
  \end{cases}
  $$

#### 非概率模型

$$
\begin{cases}
线性模型\\
非线性模型
\end{cases}
$$

线性模型

- 感知机
- 线性SVM
- K近邻
- K均值
- 潜在语义分析

非线性模型

- 核函数SVM

  核函数：$线性不可分的低维空间\rightarrow 线性可分的高维空间$

  核技巧 
  $$
  R^2:x=(x^{(1)},x^{(2)})^T\\
  \Phi(x)R^2\rightarrow \mathcal{H}:\Phi\left((x^{(1)})^2,\sqrt{2}x^{(1)}x^{(2)},(x^{(2)})^2\right)
  $$

- AdaBoost

- 神经网络

#### 逻辑斯蒂回归

![5b09f9f1ce4663eb10ab3428828398c](1-机器学习/5b09f9f1ce4663eb10ab3428828398c.jpg)

将线性回归模型 $\omega^T x+b=0$ 代入 $z$ ，归一化可得到概率分布，故逻辑斯蒂回归既是概率模型又是非概率模型

### 1.2.4 按学习任务分类

$$
\begin{cases}
监督学习&基于已知类别的训练数据进行学习\\
无监督学习&基于未知类别的训练数据进行学习\\
半监督学习&同时使用已知类别和未知类别的数据进行学习
\end{cases}
$$

![image-20230920173918885](1-机器学习/image-20230920173918885.png)

#### 监督学习

> 从标注的数据中学习预测模型
>
> - 标注：已知实例的分类，某些特征的取值

本质：学习输入与输出间映射的统计规律

##### 分类

根据输入输出类型：

![image-20230124183519877](1-机器学习/image-20230124183519877.png)

- 分类问题：输出变量为有限个离散变量，SP：二分类问题
- 回归问题（预测）：输入变量与输出变量均为连续变量
- 标注问题：输入变量和输出变量均为变量序列

##### 符号表示

输入变量：$X$ ，取值空间 $x\in \chi(所有可能取值集合)$ ——输入空间   

输出变量：$Y$ ——输出空间

每个具体输入：实例(instance) 用特征向量 (feature vcector) 表示

- $实例:线性空间中的一个点\in 特征空间$

$$
输入实例 x 的特征向量\begin{cases}
x=\left(
\begin{aligned}
&x^{(1)}\\
&x^{(2)}\\
&\vdots\\
&x^{(i)}\\
&\vdots\\
&x^{(m)}
\end{aligned}
\right)表示第 i 个特征的取值\\
x_j=\left(
\begin{aligned}
&x_j^{(1)}\\
&x_j^{(2)}\\
&\vdots\\
&x_j^{(i)}\\
&\vdots\\
&x_j^{(m)}
\end{aligned}
\right)表示第j个变量的第i个特征的取值
\end{cases}
$$

 **注** ：$特征空间\neq 输入空间$

训练数据集：
$$
T=\{(x_1,y_1),(x_2,y_2),\cdots,(x_n,y_n)\}
$$
联合概率分布：给出 $X$ 与 $Y$ 之间遵循的关系——$P(X,Y)$

假设空间： 输入到输出的映射由模型表示 $\in$ 假设空间 hypothesis space 所有可能的模型的集合

- 概率模型：$P(Y\vert X)$ 条件概率分布
- 决策函数：$Y=f(X)$

##### 形式化

![9d1eb023d4df908f9c67694a385c56c](1-机器学习/9d1eb023d4df908f9c67694a385c56c.jpg)

学习的模型分为概率模型和非概率模型

- 概率模型由条件概率表示，在预测时，通过 $arg\max\limits_{y}P(y\vert x)$ 得到输出
- 非概率模型由决策函数表示，在预测时，给出一个输出结果

##### 特征

- 数据有标注
- 输入产生相应的输出
- 本质是学习输入与输出映射的统计规律

#### 无监督模型

> 从无标注的数据中学习预测模型

##### 特征

- 数据无标注——自然得到的数据
- 预测模型：每个输出都是对输入的分析结果，表示数据的类别（聚类）、转换（降维）、概率估计
- 本质是学习数据中的统计规律与潜在结构

##### 符号表示

$\chi$ ：输入空间

$z$ ：隐式结构

- 降维
- 硬聚类：一对一，只属于一个类别
- 软聚类：一对多，可能属于多个类别

模型：$\begin{cases}z=g_{\theta}(x)\\P_{\theta}(z\vert x),P(x\vert z)\end{cases}$

$\mathcal{H}$ ：所有可能模型的集合——假设空间

训练数据：$U=\left\{x_1,x_2,\cdots,x_n\right\}$ ，$x_i$ 表示样本

##### 形式化

![30e90e35f46a686f6029cb57dc899a4](1-机器学习/30e90e35f46a686f6029cb57dc899a4.jpg)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       

#### 强化学习

系统与环境连续互动中学习最优行为策略

![ab8f539c5ec557313d708d1f6b82bdb](1-机器学习/ab8f539c5ec557313d708d1f6b82bdb.jpg)

#### 半监督学习

少量标注，大量未标注数据

#### 主动学习

机器找到对学习最有帮助的实例，给出实例让人标注 

### 1.2.5 按技巧分类

- 贝叶斯学习
- 核方法

#### 贝叶斯方法

>  利用贝叶斯原理，计算在给数据下，模型的后验概率 $P(\theta\vert D)$ ，并进行模型估计、数据预测 $P(X\vert D)=\int P(X\vert \theta,D)P(\theta\vert D)d\theta$

##### 特点

- 模型参数、未知量用变量表示
- 使用模型的先验概率

##### 步骤

1. $D:数据,\theta:参数$ 

   后验概率 $P(\theta\vert D)=\frac{P(\theta)P(D\vert \theta)}{P(D)}$ 变先验 $P(\theta)$

2. 预测，并计算期望

   $P(X\vert D)=\int P(x\vert \theta,D)P(\theta\vert D)d\theta$

取贝叶斯估计最大，可得到极大似然最大
$$
D\xrightarrow{MLE}\hat{\theta}=arg\max\limits_{\theta}P(D\vert \theta)\\
D\xrightarrow{Bayesian}\hat{\theta}=arg\max\limits_{\theta}P(\theta\vert D)=arg\max\limits_{\theta}\frac{P(D\vert \theta)P(\theta)}{P(D)}
$$

- $P(D\vert \theta)$ 似然概率，在已知参数 $\theta$ 取值时，取得数据 $D$ 的概率

  对于极大似然估计，目标是调整参数 $\theta$ 使数据 $D$ 出现的概率最大化，即令 $L(\theta)=P(D\vert \theta)\xlongequal{样本iid}\prod\limits_{i=1}^nP(x_i\vert \theta)$ 最大化，此时的 $\hat{\theta}$ 作为参数的估计值

- $P(\theta)$ ：为先验知识，通过统计数据可得，作为已知数据

  $P(D)$ 是固定的，后验概率 $P(\theta\vert D)$ 可以通过计算似然概率与先验概率求得 

  贝叶斯估计：使后验概率最大的 $\hat{\theta}$ 为贝叶斯估计的参数

所以重点来到对似然概率的求解

#### 核方法

> 使用核函数表示和学习非线性模型，可以将线性模型扩展到非线性模型

- SVM
- 核PCA
- K均值

显式定义：$输入空间\rightarrow特征空间，进行内积运算$ 
$$
输入空间 <x_1,x_2>\\
\downarrow\\
特征空间 <\phi(x_1),\phi(x_2)>
$$
隐式定义：直接定义核函数，在输入空间中内积运算
$$
K(x_1,x_2)=<\phi(x_1),\phi(x_2)>
$$

## 





## 1.5 监督学习

监督学习假定训练数据满足独立同分布，并根据训练数据学习出一个由输入到输出的映射模型

- 所有可能的映射模型共同构成了假设空间

监督学习的任务是在假设空间中根据特定的误差准则找到最优的模型，形式为 $\begin{cases}决策函数Y=f(X)\\条件概率分布P(Y\vert X)\end{cases}$

### 1.5.1 学习方法

#### 生成方法

> 关注 X，Y的真实状态，强调数据本身（掌握所有语言再判断）

首先学习X，Y的联合概率分布 $P(X,Y)$ ，再求出条件概率分布 $P(Y\vert X)$ 

- 反映同类数据的相似度
- 学习的收敛速度快：当样本容量增加，学到的模型更快，收敛于真实模型
- 当存在隐变量时，用生成方法

#### 判别方法

> 关注给定输入X，有什么样的输出Y，强调数据边界（语言关键词）

直接学习决策函数 $Y=f(X)$ 或条件概率 $P(Y\vert X)$

- 反映数据的差异
- 学习难度小，准确率高
- 对数据进行抽象，定义特征并使用特征简化学习问题
- 具有更高的准确率和更简单的使用方式

### 1.5.2 模型

#### 生成模型

由生成方法学习到的模型为生成模型，**遍历所有结果，取概率最大的为结果**

- 朴素贝叶斯

#### 判别模型

由判别方法生成的模型为判别模型，**直接得到结果**

- 感知机
- K近邻
- 逻辑斯蒂回归
- 最大熵模型
- SVM

### 1.5.3 监督学习应用

#### 分类问题

> 输出为有限个离散值

![image-20230904112638148](1-机器学习/image-20230904112638148.png)

##### 二分类问题

T：预测正确，P：预测为正类

F：预测错误，N：预测为负类
$$
\begin{array}{c|c|l}
预测正误&预测结果&备注\\
\hline
T&P&将正类归为正类\\
T&N&将负类归为负类\\
F&P&将负类归为正类\\
F&N&将正类归为负类
\end{array}
$$
当 $FP$ 减小，$FN$ 会增大

**指标**
$$
准确率=\frac{\vert 预测正确的\vert}{\vert 总\vert}=\frac{TP+TN}{\vert 总\vert}\\
错误率=\frac{\vert 预测错误的\vert}{\vert 总\vert}=\frac{FP+FN}{\vert 总\vert}\\
精确率P=\frac{预测对的正类}{\vert 预测为正类\vert}=\frac{TP}{TP+FP}——推荐，少而精准\\
召回率R=\frac{\vert预测对的正类\vert}{\vert 真正的正类\vert}=\frac{TP}{TP+FN}——预测癌症，宁可错杀
$$
![image-20230904115212011](1-机器学习/image-20230904115212011.png)

精确率（查准率）与召回率（查全率）是相互矛盾的，在不同模型中要是用不同评价指标

- $P$ 越大，则 $R$ 越小

**调和均值**
$$
\frac{2}{F_1}=\frac{1}{P}+\frac{1}{R}=\frac{TP+FP}{TP}+\frac{TP+FN}{TP}=\frac{2TP+FN+FP}{TP}\\
F_1=\frac{TP}{2TP+FN+FP}
$$

#### 标注问题

$$
分类问题\xrightarrow{推广}标注问题\xrightarrow{简单形式}结构预测
$$

输入：观测序列

- $x_i=(x_i^{(1)},x_i^{(2)},\cdots,x_i^{(n)})$ 表示一个样本在不同阶段的取值

输出：标记序列/状态序列

- $y_i=(y_i^{(1)},y_i^{(2)},\cdots,y_i^{(n)})$ 表示输出在不同阶段的值

#### 回归问题

> 用于预测输入变量和输出变量的关系，输入与输出之间的映射函数 $\iff$ 函数拟合

学习+预测

![image-20230904115457046](1-机器学习/image-20230904115457046.png)

变量个数—— $n$ 大小

特征数量 $\begin{cases}一元回归——一个特征维度\\多元回归——多个特征维度\end{cases}$

**平方损失函数MSE(mean square error)** ：$\frac{1}{2}[\hat{f}(x_i)-y_i]^2$

- 最小二乘法求解LMS（least mean square）
- MSE最小化 $\iff$ 极大似然估计

---

对于复杂的现实问题，很难用已有的函数进行拟合

神经网络逼近 $f(x)$ ——预测问题

![image-20230124170836500](1-机器学习/image-20230124170836500.png)

概率拟合 贝叶斯——分类问题

$P(0\vert X)>P(1\vert X)$ 则分类为0

## 1.6 频率派与贝叶斯派

### 1.6.1 频率派

频率本身会随机波动，但随着重复实验的次数不断增加，特定事件出现的频率值会呈现出稳定性，逐渐趋近于某个常数

从事件发生的频率认识概率的方法称为 “频率学派”。概率被认为是一个独立可重复实验中，单个结果出现频率极限。

**稳定的频率是统计规律性的体现** ，用其表征事件发生的可能性是一种合理的思路

频率学派依赖的是古典概型。由于古典概型只描述单个随机事件，并不能刻画两个随机事件之间的关系。所以引入的 **条件概率** ，进一步得出 **全概率公式** 。
$$
P(A)=\sum_\limits{i=1}^nP(A\vert B_i)\cdot P(B_i)
$$
全概率公式代表了频率派解决问题的思路：先做出一些假设 $P(B_i)$ ，再在这些假设下讨论随机事件的概率 $P(A\vert B_i)$ 

### 1.6.2 贝叶斯派

**逆概率** ：由全概率公式调整得来，即在事件结果 $P(A)$ 确定的条件下，推断各种假设发生的可能性

通过贝叶斯公式，可以将后验概率 $P(D\vert H)$ 转变为先验概率  $P(H)$
$$
P(H\vert D)=\frac{P(D\vert H)P(H)}{P(D)}
$$

- $P(H)$ ：先验概率，假设成立的概率
- $P(D\vert H)$ ：似然概率
- $P(H\vert D)$ ：后验概率，已知结果下情况下假设成立的概率

贝叶斯定理提供了解决问题的新思路：根据观测结果寻找最佳的理论解释

### 1.6.3 区别

**频率学派** 认为假设是客观存在且不会改变的，即存在固定的先验分布，需要通过 **最大似然估计** 确定概率分布的类型和参数，以此作为基础进行概率推演。

**贝叶斯学派** 认为固定的先验分布是不存在的，即参数本身是随机数。假设本身取决于结果，是不确定的、可以修正的。数据的作用就是对假设不断修正，通过 **贝叶斯估计** 使后验概率最大化 。 

----

从 **参数估计** 角度也能体现两种思想的差距

由于实际任务中可供使用的训练数据有限，因而需要对概率分布的参数进行估计。

最大似然估计（最大似然概率 $P(D\vert H)$）的思想是使训练数据出现的概率最大化，以此确定概率分布中的未知参数

贝叶斯方法（最大后验概率 $P(H\vert D)$）：根据训练数据和已知的其他条件，使未知参数出现的可能性最大化，并选取最大概率对应的未知参数

- 还需要额外的信息 ——先验概率 $P(H)$ 

## 1.7 常用定理

#### 丑小鸭定理

> 丑小鸭与白天鹅之间的区别和两只白天鹅之间的区别一样大

世界上不存在相似性的客观标准，一切相似性的标准都是主观的

即针对同一问题的同一训练集设计的假设集，**假设与假设之间的差距很大**。

选择什么样的假设最合适是 归纳偏好 要回答的问题。

### 1.7.4 归纳偏好

任何机器学习必有其偏好：相信什么模型是更好的、什么假设是更合理的，，这些假设就被称为 **归纳偏好**

- 最近邻分类器中，假设在特征空间中，一个小的局部区域中的大部分样本同属一类
- 朴素贝叶斯分类器中，假设每个特征的条件概率是互相独立的——先验

学习算法的归纳偏好是否与问题本身匹配，直接决定了算法是否能取得很好的性能

#### 奥卡姆剃刀

归纳偏好的一般原则是：简单模型的泛化能力更好，但 **评价模型是否简单也不容易**

##### 最小描述长度

对一个数据集 $D$ ，最好的模型 $f\in \mathcal{F}$ 会使得数据集的压缩效果最好，即编码长度最小

贝叶斯角度

![image-20230922103751580](1-机器学习/image-20230922103751580.png)

![image-20230922104107109](1-机器学习/image-20230922104107109.png)

#### NFL定理——模型选择要具体问题具体分析









